{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a5523de",
   "metadata": {},
   "source": [
    "# Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cee90e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 13:39:51.120929: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-06 13:39:51.153728: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-06 13:39:51.154176: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-06 13:39:51.739686: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31ec7904307f40daaa1b6f4c4fb47aaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b5dc725906542749ac3cc22fca3d604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba6d42cf7402494c957e20a2a4b3a9da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/321 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca4abb7b066248e794e863fbb54efe43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "198b11f557a44d429a0f8bfd121d0f16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertForQuestionAnswering\n",
    "from transformers import BertTokenizer\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "weight_path = \"kaporter/bert-base-uncased-finetuned-squad\"\n",
    "# loading tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(weight_path)\n",
    "#loading the model\n",
    "model = BertForQuestionAnswering.from_pretrained(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f76f576",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = ['The appellant having been convicted under Section 80 of the Karnataka Police Act, 1963 (for short, ‘the 1963 Act’) has filed the present appeal.',]\n",
    "\n",
    "question = [\"On what Section the appelant were convicted?\"]\n",
    "\n",
    "answer = \"Section 80\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fa6ac5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have about 5 tokens generated\n",
      " \n",
      "Some examples of token-input_id pairs:\n",
      "[CLS] : 101\n",
      "[UNK] : 100\n",
      "[SEP] : 102\n",
      "[UNK] : 100\n",
      "[SEP] : 102\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(question, context)\n",
    "print (f'We have about {len(input_ids)} tokens generated')\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "print(\" \")\n",
    "print('Some examples of token-input_id pairs:')\n",
    "\n",
    "for i, (token,inp_id) in enumerate(zip(tokens,input_ids)):\n",
    "    print(token,\":\",inp_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc631fd",
   "metadata": {},
   "source": [
    "BERT Inputs\n",
    "\n",
    "Word piece embedding <br>\n",
    "Positional embedding <br>\n",
    "Segmentation embedding. <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12899b26",
   "metadata": {},
   "source": [
    "Segmentation emebdding will be 0 for all tokens related to question and 1 for all tokens related to Context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9ccd268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "sep_idx = tokens.index('[SEP]')\n",
    "\n",
    "# we will provide including [SEP] token which seperates question from context and 1 for rest.\n",
    "token_type_ids = [0 for i in range(sep_idx+1)] + [1 for i in range(sep_idx+1,len(tokens))]\n",
    "print(token_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78742c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer: \n"
     ]
    }
   ],
   "source": [
    "out = model(torch.tensor([input_ids]), \n",
    "                token_type_ids=torch.tensor([token_type_ids]))\n",
    "\n",
    "start_logits,end_logits = out['start_logits'],out['end_logits']\n",
    "# Find the tokens with the highest `start` and `end` scores.\n",
    "answer_start = torch.argmax(start_logits)\n",
    "answer_end = torch.argmax(end_logits)\n",
    "\n",
    "answer = ''.join(tokens[answer_start:answer_end])\n",
    "print('Predicted answer:', answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87139d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56a1ef9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97923fc83c1b410ea4c848a71291c5e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a971e30ca07b4d3095a72df049b1607e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/2.36k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d9452c8ccef445281bd59a177259bdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/7.67k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset squad/plain_text to /home/ujjawal/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9190a8de6b24253be216afc6cddb61e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16a26d7df544c00a194bf886b537d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/8.12M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d075c674fcf4faab12c6067c23330c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.05M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a575a530b169419e847dd8bc56c0b411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/87599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10570 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset squad downloaded and prepared to /home/ujjawal/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69151ce7d8c1408aa8b2f69ff3df63f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 87599\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"squad\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75c640d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/87599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 0\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"].filter(lambda x: len(x[\"answers\"][\"text\"]) != 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23033534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 8000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"] = dataset[\"train\"].select([i for i in range(8000)])\n",
    "dataset[\"validation\"] = dataset[\"validation\"].select([i for i in range(2000)])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f76dc3b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca073ca004b943229e6dce2a7667df7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96c1b42c2bc4191a74e807fbf561c50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df4cb59c61c48728c4ce483d09780dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cdb9048047d41d293eac681e0df49a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 4 examples gave 2 features.\n",
      "Here is where each comes from: [0, 0].\n",
      "Question:  To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n",
      " \n",
      "Context :  Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n",
      " \n",
      "Answer:  ['Saint Bernadette Soubirous']\n",
      "--------------------------------------------------\n",
      "Context piece 1\n",
      "[SEP] architecturally, the school has a catholic character. atop the main building's gold dome is a golden statue of the virgin mary. immediately in front of the main building and facing it, is a copper statue of christ with arms upraised with the legend \" venite ad me omnes \". next to the main building is the basilica of the sacred heart. immediately behind the basilica is the grotto, a marian place of prayer and reflection. it is a replica of the grotto at lourdes, france where the virgin mary reputedly appeared to saint bernadette soubirous in 1858. at the end of the main drive ( and in a direct line that connects through 3 statues [SEP]\n",
      " \n",
      "Context piece 2\n",
      "[SEP] sacred heart. immediately behind the basilica is the grotto, a marian place of prayer and reflection. it is a replica of the grotto at lourdes, france where the virgin mary reputedly appeared to saint bernadette soubirous in 1858. at the end of the main drive ( and in a direct line that connects through 3 statues and the gold dome ), is a simple, modern stone statue of mary. [SEP]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# model_checkpoint = \"bert-base-cased\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "trained_checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(trained_checkpoint)\n",
    "\n",
    "context = dataset[\"train\"][0][\"context\"]\n",
    "question = dataset[\"train\"][0][\"question\"]\n",
    "answer = dataset[\"train\"][0][\"answers\"][\"text\"]\n",
    "\n",
    "\n",
    "inputs = tokenizer(\n",
    "    question,\n",
    "    context,\n",
    "    max_length=160,\n",
    "    truncation=\"only_second\",  # only to truncate context\n",
    "    stride=70,  # no of overlapping tokens  between concecute context pieces\n",
    "    return_overflowing_tokens=True,  #to let tokenizer know we want overflow tokens\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"The 4 examples gave {len(inputs['input_ids'])} features.\")\n",
    "print(f\"Here is where each comes from: {inputs['overflow_to_sample_mapping']}.\")\n",
    "\n",
    "print('Question: ',question)\n",
    "print(' ')\n",
    "print('Context : ',context)\n",
    "print(' ')\n",
    "print('Answer: ', answer)\n",
    "print('--'*25)\n",
    "\n",
    "for i,ids in enumerate(inputs[\"input_ids\"]):\n",
    "    print('Context piece', i+1)\n",
    "    print(tokenizer.decode(ids[ids.index(102):]))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da45e47d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(8000, 200)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "del tokenizer\n",
    "trained_checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(trained_checkpoint)\n",
    "\n",
    "def train_data_preprocess(examples):\n",
    "    \n",
    "    \"\"\"\n",
    "    generate start and end indexes of answer in context\n",
    "    \"\"\"\n",
    "    \n",
    "    def find_context_start_end_index(sequence_ids):\n",
    "        \"\"\"\n",
    "        returns the token index in whih context starts and ends\n",
    "        \"\"\"\n",
    "        token_idx = 0\n",
    "        while sequence_ids[token_idx] != 1:  #means its special tokens or tokens of queston\n",
    "            token_idx += 1                   # loop only break when context starts in tokens\n",
    "        context_start_idx = token_idx\n",
    "    \n",
    "        while sequence_ids[token_idx] == 1:\n",
    "            token_idx += 1\n",
    "        context_end_idx = token_idx - 1\n",
    "        return context_start_idx,context_end_idx  \n",
    "    \n",
    "    \n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    context = examples[\"context\"]\n",
    "    answers = examples[\"answers\"]\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        context,\n",
    "        max_length=512,\n",
    "        truncation=\"only_second\",\n",
    "        stride=128,\n",
    "        return_overflowing_tokens=True,  #returns id of base context\n",
    "        return_offsets_mapping=True,  # returns (start_index,end_index) of each token\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    \n",
    "    for i,mapping_idx_pairs in enumerate(inputs['offset_mapping']):\n",
    "        context_idx = inputs['overflow_to_sample_mapping'][i]\n",
    "    \n",
    "        # from main context\n",
    "        answer = answers[context_idx]\n",
    "        answer_start_char_idx = answer['answer_start'][0]\n",
    "        answer_end_char_idx = answer_start_char_idx + len(answer['text'][0])\n",
    "\n",
    "    \n",
    "        # now we have to find it in sub contexts\n",
    "        tokens = inputs['input_ids'][i]\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "   \n",
    "        # finding the context start and end indexes wrt sub context tokens\n",
    "        context_start_idx,context_end_idx = find_context_start_end_index(sequence_ids)\n",
    "    \n",
    "        #if the answer is not fully inside context label it as (0,0)\n",
    "        # starting and end index of charecter of full context text\n",
    "        context_start_char_index = mapping_idx_pairs[context_start_idx][0]\n",
    "        context_end_char_index = mapping_idx_pairs[context_end_idx][1]\n",
    "    \n",
    "\n",
    "        #If the answer is not fully inside the context, label is (0, 0)\n",
    "        if (context_start_char_index > answer_start_char_idx) or (\n",
    "            context_end_char_index < answer_end_char_idx):\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "    \n",
    "        else:\n",
    "\n",
    "            # else its start and end token positions\n",
    "            # here idx indicates index of token\n",
    "            idx = context_start_idx\n",
    "            while idx <= context_end_idx and mapping_idx_pairs[idx][0] <= answer_start_char_idx:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)  \n",
    "        \n",
    "\n",
    "            idx = context_end_idx\n",
    "            while idx >= context_start_idx and mapping_idx_pairs[idx][1] > answer_end_char_idx:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "    \n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs\n",
    "    \n",
    "train_sample = dataset[\"train\"].select([i for i in range(200)])\n",
    "    \n",
    "train_dataset = train_sample.map(\n",
    "    train_data_preprocess,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"train\"].column_names\n",
    ")\n",
    "\n",
    "len(dataset[\"train\"]),len(train_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26fca324",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-07 09:20:09.008563: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-07 09:20:09.103033: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-07 09:20:09.103464: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-07 09:20:09.891637: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc84a1488c0c402f8e73af4da2a3ec27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/686 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43fcc67519214dd09466bb21c5a6298d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/431M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b402ab29d324146b50e9c964a092ea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/320 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fa7a3fe20e845f4bf6cbe4137bb050d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ad4fe0e67b34d22a7fe1f45ef7077f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac7e0ffd9724d5ca13f2a2c63be9233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.28610795736312866,\n",
       " 'start': 43,\n",
       " 'end': 87,\n",
       " 'answer': 'Section 80 of the Karnataka Police Act, 1963'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Replace this with your own checkpoint\n",
    "model_checkpoint = \"huggingface-course/bert-finetuned-squad\"\n",
    "question_answerer = pipeline(\"question-answering\", model=model_checkpoint)\n",
    "\n",
    "context = \"\"\"\n",
    "The appellant having been convicted under Section 80 of the Karnataka Police Act, 1963 (for short, ‘the 1963 Act’) has filed the present appeal.\n",
    "\"\"\"\n",
    "question = \"On what Section the appelant were convicted?\"\n",
    "question_answerer(question=question, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cdcbb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
